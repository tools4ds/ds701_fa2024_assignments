{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"assignment7.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Neural Networks using PyTorch\n",
    "\n",
    "This assignment aims to give you practical experience in building, training, and evaluating neural networks using PyTorch. You'll apply neural networks to a real-world dataset and gain hands-on experience with industry-standard tools and techniques.\n",
    "\n",
    "[PyTorch](https://pytorch.org/) is an open-source machine learning library developed by Facebook's AI Research lab. It provides a flexible and efficient platform for building and training neural networks. It supports all kinds of applications: computer vision, natural language processing, and reinforcement learning. PyTorch is an extremely popular choice for both research and production environments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 \n",
    "\n",
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We'll be using the [CIFAR-100 dataset](https://www.cs.toronto.edu/~kriz/cifar.html). It consists of 60,000 32x32 color images divided into 100 different classes, with 600 images per class. The dataset is split into 50,000 training images and 10,000 test images. The 100 classes are grouped into 20 superclasses. For example, the superclass \"fish\" contains classes like \"aquarium fish\", \"flatfish\", \"ray\", \"shark\", and \"trout\". This makes CIFAR-100 more challenging than similar datasets like CIFAR-10, as it requires models to make more fine-grained distinctions between classes.\n",
    "\n",
    "PyTorch has a library called `torchvision` that provides a comprehensive set of tools for working with images and videos. We can load CIFAR-100 (and others!) using `torchvision.datasets`. \n",
    "\n",
    "We're also defining some transformations that will be performed on the images when loading the dataset. \n",
    "\n",
    "**Question 1:** Your first task two-fold: \n",
    "\n",
    "1. Define the `training_set` and `validation_set` variables to the appropriate splits of the CIFAR-100 dataset. Don't forget to apply the transforms. Use [this documentation page](https://pytorch.org/vision/main/generated/torchvision.datasets.CIFAR100.html) for reference.\n",
    "2. Define the `training_loader` and `validation_loader` varibles to dataloaders for the two datasets we instantiated before. Provide a batch size of 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Note that this will download the dataset into a directory called 'data' in your current working directory\n",
    "training_set = ...\n",
    "validation_set = ...\n",
    "\n",
    "# To simplify the data loading, we will use a DataLoader object provided by PyTorch with a batch size of 64\n",
    "training_loader = ...\n",
    "validation_loader = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training set has {len(training_set)} images\")\n",
    "print(f\"Validation set has {len(validation_set)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Each image is of size {training_set[0][0].size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can view the classes using `.classes`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = training_set.classes\n",
    "print(f\"Classes: {classes}\")\n",
    "print(f\"Number of classes: {len(classes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, the `training_loader` is defined as an iterable that returns images in\n",
    "batches. We can see how many iterations are required to return unique batches of\n",
    "our training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training loader has {len(training_loader)} batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some of the images.  You can re-run this cell to look at a different batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(training_loader)) # This loads a batch of images and their labels\n",
    "\n",
    "# Display the images\n",
    "fig, axs = plt.subplots(1, 8, figsize=(20, 5))\n",
    "for i, ax in enumerate(axs):\n",
    "    ax.imshow(images[i].permute(1, 2, 0))\n",
    "    ax.set_title(classes[labels[i]])\n",
    "    ax.axis('off')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the histograms of each channel of the batch of images as well\n",
    "as compute the mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "images, labels = next(iter(training_loader))\n",
    "\n",
    "# Assuming `images` is a batch of images with shape (batch_size, channels, height, width)\n",
    "batch_size, channels, height, width = images.shape\n",
    "\n",
    "# Compute mean and std for each channel\n",
    "mean = images.mean(dim=[0, 2, 3])\n",
    "std = images.std(dim=[0, 2, 3])\n",
    "\n",
    "print(f\"Mean: {mean}\")\n",
    "print(f\"Std: {std}\")\n",
    "\n",
    "# Plot histograms for each channel\n",
    "fig, axs = plt.subplots(1, channels, figsize=(15, 5))\n",
    "for i in range(channels):\n",
    "    axs[i].hist(images[:, i, :, :].flatten().numpy(), bins=50, color='blue', alpha=0.7)\n",
    "    axs[i].set_title(f'Channel {i+1} Histogram')\n",
    "    axs[i].set_xlabel('Pixel Values')\n",
    "    axs[i].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 \n",
    "\n",
    "## Building and Training a Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we will build a Convolutional Neural Network (CNN) from scratch to classify the images in our dataset. CNNs are particularly well-suited for image classification tasks because they can automatically learn hierarchical features from the input images through their convolutional layers.\n",
    "# \n",
    "We will:\n",
    "1. Define a CNN architecture with convolutional layers, pooling layers, and fully connected layers\n",
    "2. Train the model using our training data\n",
    "3. Evaluate the model's performance on the test set\n",
    "\n",
    "The CNN will need to learn to distinguish between our 100 different classes of images by identifying relevant features and patterns in the input data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 2:** Define a class called `CNN` which we will use to instantiate our model. Use the `torch.nn` module to define it's layers and the `torch.nn.functional` library to define activations. Your model should have at least one convolutional layer. You are free to define the rest of the layers model and activations - for example, you could have a series of convolutional layers followed by a series of linear layers. We encourage you to experiment and get your prediction accuracy as high as possible! \n",
    "\n",
    "Use [the course notes on CNNs](https://tools4ds.github.io/DS701-Course-Notes/25-NN-III-CNNs.html#define-a-cnn-in-pytorch), [the discussion notebook on neural networks](https://github.com/tools4ds/ds701_fa2024_assignments/blob/main/discussions/discussion11/discussion11-NN.ipynb) and PyTorch documentation for reference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        ...\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        ...\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Create an instance of the CNN\n",
    "model = CNN()\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3**: Define the optimizer and the loss function. Pick what's appropriate from PyTorch documentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = ...\n",
    "loss_fn = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 4:** Train the model for at least 10 epochs, and plot the performance. Define a function `train_model` that takes the training and validation dataloaders, optimizer, loss function, and the number of epochs to train.\n",
    "\n",
    "The function should return the training losses and validation accuracies. \n",
    "\n",
    "The training loop is as follows:\n",
    "\n",
    "```\n",
    "\n",
    "For each epoch:\n",
    "   Set model to training mode\n",
    "   Send model to device (GPU) using .to(device)\n",
    "   For each batch in training dataloader:\n",
    "     Get inputs and labels from batch. Send inputs to GPU device. \n",
    "\n",
    "     Zero out gradients\n",
    "     Forward pass through model\n",
    "     Calculate loss\n",
    "     Backward pass\n",
    "     Update weights\n",
    "   \n",
    "   Set model to evaluation mode - remember, no backprop/gradient calculation!\n",
    "   For each batch in validation dataloader:\n",
    "     Get inputs and labels from batch\n",
    "     Forward pass through model\n",
    "     Calculate validation loss\n",
    "   \n",
    "   Store training and validation metrics. Print them if you'd like. \n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR FASTER TRAINING, USE GPU IF AVAILABLE\n",
    "device = torch.device('cuda' if torch.cuda.is_available(\n",
    ") else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize lists to store metrics\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Training loop\n",
    "def train_model(model, training_loader, validation_loader, optimizer, loss_fn, device, EPOCHS):\n",
    "    # Initialize lists to store metrics\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in tqdm(range(EPOCHS), desc=\"Epochs\"):\n",
    "        model.train()  # Set model to training mode\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        # Training phase\n",
    "        for inputs, labels in training_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "                        \n",
    "            outputs = model(inputs)  # Forward pass\n",
    "\n",
    "            # YOUR CODE HERE\n",
    "            ...\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            predicted = torch.argmax(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(training_loader)\n",
    "        epoch_acc = 100 * correct / total\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accuracies.append(epoch_acc)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in validation_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                outputs = ...\n",
    "                loss = ...\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "\n",
    "                #_, predicted = torch.max(outputs.data, 1)\n",
    "                predicted = torch.argmax(outputs, 1)\n",
    "                # print(f\"predicted: {predicted}\")\n",
    "                # print(f\"labels: {labels}\")\n",
    "                \n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_loss = val_loss / len(validation_loader)\n",
    "        val_acc = 100 * correct / total\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{EPOCHS}]')\n",
    "        print(f'Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.2f}%')\n",
    "        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "        print('-' * 60)\n",
    "    \n",
    "    return train_losses, val_losses, train_accuracies, val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPOCHS = ...\n",
    "\n",
    "train_losses, val_losses, train_accuracies, val_accuracies = train_model(model, \n",
    "                                                                         training_loader, \n",
    "                                                                         validation_loader, \n",
    "                                                                         optimizer, \n",
    "                                                                         loss_fn, \n",
    "                                                                         device, \n",
    "                                                                         EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 5**: Plotting model performance. \n",
    "\n",
    "Create two plots: \n",
    "- Training loss against epochs\n",
    "- Validation accuracy epochs\n",
    "\n",
    "Make sure your plots are appropriately labeled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "Compare the loss and accuracy plots for training versus validation. What do you notice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Replace this text with your answer.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1": {
     "name": "q1",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> def test_q1(training_set, validation_set):\n...     assert isinstance(training_set, torch.utils.data.Dataset), 'training_set must be a Dataset'\n...     assert isinstance(validation_set, torch.utils.data.Dataset), 'validation_set must be a Dataset'\n...     assert len(training_set) == 50000, 'training_set must have 50000 images'\n...     assert len(validation_set) == 10000, 'validation_set must have 10000 images'\n...     assert training_set[0][0].shape == (3, 32, 32), 'training_set images must be 32x32 with 3 color channels'\n...     assert validation_set[0][0].shape == (3, 32, 32), 'validation_set images must be 32x32 with 3 color channels'\n...     assert training_loader.batch_size == 64, 'training_loader must have a batch size of 64'\n...     assert validation_loader.batch_size == 64, 'validation_loader must have a batch size of 64'\n>>> test_q1(training_set, validation_set)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> def test_q2(model):\n...     assert isinstance(model, nn.Module), 'model must be a PyTorch Module'\n...     assert len(list(model.parameters())) > 0, 'model must have parameters'\n...     assert len(list(model.children())) > 0, 'model must have at least one layer'\n...     assert any((isinstance(layer, nn.Conv2d) for layer in model.children())), 'model must have at least one convolutional layer'\n...     last_layer = list(model.children())[-1]\n...     assert last_layer.out_features == 100, 'last layer must have 100 output features'\n...     try:\n...         model = CNN()\n...     except Exception as e:\n...         raise AssertionError(f'Failed to instantiate model: {e}')\n>>> test_q2(model)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> def test_q3(optimizer, loss_fn):\n...     from torch.nn.modules.loss import _Loss\n...     assert isinstance(optimizer, torch.optim.Optimizer), 'optimizer must be a PyTorch Optimizer'\n...     assert isinstance(loss_fn, _Loss), 'loss_fn must be a PyTorch Loss function'\n>>> test_q3(optimizer, loss_fn)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
